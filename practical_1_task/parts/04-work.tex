\chapter{Основные теоретические сведения}
Основная вычислительная системы (так называемая хост-подсистема) берет на себя функции управления запуском вычислительных задач, поддержкой сетевых подключений, обработкой и балансировкой нагрузки. В хост-подсистему входят два многоядерных ЦПУ по 26 ядер каждый, оперативная память на 1 Тбайт и дополнительная энергонезависимая память на 8 Тбайт, где хранятся атрибуты вершин и ребер графа, буферизируются поступающие запросы на обработку и визуализацию графов, хранятся временные данные об изменениях в графах. В хост-подсистеме используется процессор с архитектурой x86 для обеспечения сетевого взаимодействия и связи системы с внешним миром. Указанные функции реализованы в Программном ядре хост-подсистемы (host software kernel) – программном обеспечении, взаимодействующим с подсистемой обработки графов через шину PCIe.

Основу взаимодействия подсистем при обработке графов составляет передача блоков данных и коротких сообщений между GPC и хост-подсистемой. Для передачи сообщений для каждого GPC реализованы два аппаратных FIFO буфера на 512 записей: Host2GPC для передачи от хост-подсистемы к ядру, и GPC2Host для передачи в обратную сторону.

Обработка начинается с того, что собранное программное ядро (software kernel) загружается в локальное ОЗУ одного или нескольких CPE (микропроцессора riscv32im). Для этого используется механизм прямого доступа к памяти со стороны хост-подсистемы. В свою очередь, GPC (один или несколько) получают сигнал о готовности образа software kernel в Глобальной памяти, после чего вызывается загрузчик, хранимый в ПЗУ CPE. Загрузчик выполняет копирование программного ядра из Глобальной памяти в ОЗУ CPE и передает управление на начальный адрес программы обработки. Предусмотрен режим работы GPC, при котором во время обработки происходит обмен данными и сообщениями. Эти два варианта работы реализуется через буферы и очереди соответственно. На рисунке 7 представлена диаграмма последовательностей первого сценария работы – вызов обработчика с передачей параметров и возвратом значения через очередь сообщений.

\chapter{Экспериментальная часть}


\section{Индивидуальное задание}

Задание практикума выполнялось по варианту 11:
Устройство формирования индексов SQL EXCEPT. Сформировать в хост-подсистеме и передать в SPE 256 записей множества A (случайные числа в диапазое 0..1024) и 256 записей множества B (случайные числа в диапазоне 0..1024). Сформировать в SPE множество C = A not B. Выполнить тестирование работы SPE, сравнив набор ключей в множестве C с ожидаемым.

\section{Результаты выполнения задания}

\subsection{Host}

\begin{lstlisting}[label=lst:host,caption=Измененный код хост-системы под индивидульное задание]
#include <iostream>
#include <stdio.h>
#include <stdexcept>
#include <iomanip>
#ifdef _WINDOWS
#include <io.h>
#else
#include <unistd.h>
#endif


#include "experimental/xrt_device.h"
#include "experimental/xrt_kernel.h"
#include "experimental/xrt_bo.h"
#include "experimental/xrt_ini.h"

#include "gpc_defs.h"
#include "leonhardx64_xrt.h"
#include "gpc_handlers.h"

#define BURST 256

union uint64 {
	uint64_t 	u64;
	uint32_t 	u32[2];
	uint16_t 	u16[4];
	uint8_t 	u8[8];
};

uint64_t rand64() {
	uint64 tmp;
	tmp.u32[0] =  rand();
	tmp.u32[1] =  rand();
	return tmp.u64;
}

static void usage()
{
	std::cout << "usage: <xclbin> <sw_kernel>\n\n";
}

#include <set>
using namespace std;


set<uint64_t> getExcept(set<uint64_t> &a, set<uint64_t> &b){
	set<uint64_t> result;
	printf("Ожидаемый результат C:\n");
	for (uint64_t el:a){
		if (b.find(el) == b.end()) {
			printf("\t%u\n", el);
			result.insert(el);
		}
	}
	
	return result;
}

int main(int argc, char** argv)
{
	set<uint64_t> a,b,c;
	unsigned int cores_count = 0;
	float LNH_CLOCKS_PER_SEC;
	
	__foreach_core(group, core) cores_count++;
	
	//Assign xclbin
	if (argc < 3) {
		usage();
		throw std::runtime_error("FAILED_TEST\nNo xclbin specified");
	}
	
	//Open device #0
	leonhardx64 lnh_inst = leonhardx64(0,argv[1]);
	__foreach_core(group, core)
	{
		lnh_inst.load_sw_kernel(argv[2], group, core);
	}
	
	
	// /*
	//  *
	//  * Запись множества из BURST key-value и его последовательное чтение через Global Memory Buffer
	//  *
	//  */
	
	
	//Выделение памяти под буферы gpc2host и host2gpc для каждого ядра и группы
	uint64_t *host2gpc_buffer[LNH_GROUPS_COUNT][LNH_MAX_CORES_IN_GROUP];
	__foreach_core(group, core)
	{
		host2gpc_buffer[group][core] = (uint64_t*) malloc(4*BURST*sizeof(uint64_t));
	}
	uint64_t *gpc2host_buffer[LNH_GROUPS_COUNT][LNH_MAX_CORES_IN_GROUP];
	__foreach_core(group, core)
	{
		gpc2host_buffer[group][core] = (uint64_t*) malloc(2*BURST*sizeof(uint64_t));
	}
	
	//Создание массива ключей и значений для записи в lnh64
	__foreach_core(group, core)
	{
		printf("Generate data\n");
		printf("\tIndex -- Value\n");
		uint64_t random_num;
		for (int i=0;i<2*BURST;i++) {
			//Первый элемент массива uint64_t - key
			random_num = rand64() % 1024;
			
			if (i < BURST){
				host2gpc_buffer[group][core][2*i+1] = i;
				//random_num = i + 250;
				a.insert(random_num);
			} else {
				host2gpc_buffer[group][core][2*i+1] = i - BURST;
				//random_num = i;
				b.insert(random_num);
			}
			
			if (i == 0)
			printf("------------A SET----------\n");
			if (i == BURST)
			printf("------------B SET----------\n");
			host2gpc_buffer[group][core][2*i] = random_num;
			//Второй uint64_t - value
			
			printf("\t%u, %u\n", host2gpc_buffer[group][core][2*i+1], host2gpc_buffer[group][core][2*i]);
		}
	}
	
	//Запуск обработчика insert_burst
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->start_async(__event__(insert_burst));
	}
	
	//DMA запись массива host2gpc_buffer в глобальную память
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->buf_write(BURS *4 * sizeof(uint64_t), (char*) host2gpc_buffer[group][core]);
	}
	
	//Ожидание завершения DMA
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->buf_write_join();
	}
	
	//Передать количество key-value
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->mq_send(BURST);
	}
	
	//Запуск обработчика для последовательного обхода множества ключей
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->start_async(__event__(search_burst));
	}
	
	//Получить количество ключей
	unsigned int count[LNH_GROUPS_COUNT][LNH_MAX_CORES_IN_GROUP];
	
	__foreach_core(group, core) {
		count[group][core] = lnh_inst.gpc[group][core]->mq_receive();
	}
	
	
	//Прочитать количество ключей
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->buf_read(count[group][core] * 2 * sizeof(uint64_t), (char*)gpc2host_buffer[group][core]);
	}
	
	//Ожидание завершения DMA
	__foreach_core(group, core) {
		lnh_inst.gpc[group][core]->buf_read_join();
	}
	
	
	bool error = false;
	set<uint64_t> res;
	//Проверка целостности данных
	__foreach_core(group, core) {
		printf("Count: %u\n", count[group][core]);
		printf("Результат полученный из SPE:\n");
		printf("\tIndex -- Value\n");
		for (int i=0; i<count[group][core]; i++) {
			uint64_t key = gpc2host_buffer[group][core][2*i];
			uint64_t value = gpc2host_buffer[group][core][2*i+1];
			res.insert(key);
			//uint64_t orig_key = host2gpc_buffer[group][core][2*value];
			printf("\tC = %u, %u\n", value, key);
			//			if (key != orig_key) {
				//				error = true;
				//			}
		}
		
		c = getExcept(a, b);
		if (res != c)
		error = true;
	}
	
	
	__foreach_core(group, core) {
		free(host2gpc_buffer[group][core]);
		free(gpc2host_buffer[group][core]);
	}
	
	if (!error)
	printf("Тест пройден успешно!\n");
	else
	printf("Тест завершен с ошибкой!\n");
	
	
	return 0;
}
\end{lstlisting}

\subsection{sw\_kernel}

\begin{lstlisting}[label=lst:swkernel,caption=Измененный код sw\_kernel под индивидульное задание]
/*
* gpc_test.c
*
* sw_kernel library
*
*  Created on: April 23, 2021
*      Author: A.Popov
*/

#include <stdlib.h>
#include <unistd.h>
#include "lnh64.h"
#include "gpc_io_swk.h"
#include "gpc_handlers.h"

#define SW_KERNEL_VERSION 26
#define DEFINE_LNH_DRIVER
#define DEFINE_MQ_R2L
#define DEFINE_MQ_L2R
#define __fast_recall__

#define TEST_STRUCTURE 1
#define A 1
#define B 2
#define C 3

extern lnh lnh_core;
extern global_memory_io gmio;
volatile unsigned int event_source;

int main(void) {
	/////////////////////////////////////////////////////////
	//                  Main Event Loop
	/////////////////////////////////////////////////////////
	//Leonhard driver structure should be initialised
	lnh_init();
	//Initialise host2gpc and gpc2host queues
	gmio_init(lnh_core.partition.data_partition);
	for (;;) {
		//Wait for event
		while (!gpc_start());
		//Enable RW operations
		set_gpc_state(BUSY);
		//Wait for event
		event_source = gpc_config();
		switch(event_source) {
			/////////////////////////////////////////////
			//  Measure GPN operation frequency
			/////////////////////////////////////////////
			case __event__(insert_burst) : insert_burst(); break;
			case __event__(search_burst) : search_burst(); break;
		}
		//Disable RW operations
		set_gpc_state(IDLE);
		while (gpc_start());
		
	}
}

//-------------------------------------------------------------
//      Получить пакет из глобальной памяти и аписат в lnh64
//-------------------------------------------------------------

void insert_burst() {
	
	//Удаление данных из структур
	lnh_del_str_sync(1);
	lnh_del_str_sync(2);
	lnh_del_str_sync(3);
	//Объявление переменных
	unsigned int count = mq_receive();
	unsigned int size_in_bytes = 4*count*sizeof(uint64_t);
	//Создание буфера для приема пакета
	uint64_t *buffer = (uint64_t*)malloc(size_in_bytes);
	//Чтение пакета в RAM
	buf_read(size_in_bytes, (char*)buffer);
	//Обработка пакета - запись
	
	// insert A set
	int i=0;
	for (; i<count; i++) {
		lnh_ins_sync(1,buffer[2*i],buffer[2*i+1]);
	}
	
	// insert B set
	for (; i<2*count; i++) {
		lnh_ins_sync(2,buffer[2*i],buffer[2*i+1]);
	}
	lnh_sync();
	free(buffer);
}


//-------------------------------------------------------------
//      Обход структуры lnh64 и запись в глобальную память 
//-------------------------------------------------------------

void search_burst() {
	
	//Ожидание завершения предыдущих команд
	lnh_sync();
	// C = A not B
	lnh_not_sync(A, B, C);
	//Объявление переменных
	// count of C set
	unsigned int count = lnh_get_num(C);
	unsigned int size_in_bytes = 2*count*sizeof(uint64_t);
	//Создание буфера для приема пакета
	uint64_t *buffer = (uint64_t*)malloc(size_in_bytes);
	//Выборка минимального ключа
	lnh_get_first(C);
	//Запись ключа и значения в буфер
	for (int i=0; i<count; i++) {
		buffer[2*i] = lnh_core.result.key;
		buffer[2*i+1] = lnh_core.result.value;
		lnh_next(C,lnh_core.result.key);
	}
	//Запись глобальной памяти из RAM
	buf_write(size_in_bytes, (char*)buffer);
	mq_send(count);
	free(buffer);
	
}
\end{lstlisting}
